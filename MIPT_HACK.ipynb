{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uquxg66y8jog"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection as selection\n",
    "from sklearn import linear_model, tree, svm, neural_network, ensemble\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JYE9N70Loh0"
   },
   "outputs": [],
   "source": [
    "metric = lambda pred, true: np.sum(np.abs(pred- true)/true)\n",
    "random_state = 42\n",
    "use_hour = True\n",
    "use_day = True\n",
    "#tune_hour = True\n",
    "#tune_day = True\n",
    "\n",
    "use_linear = True\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9-UkvJj2lGf"
   },
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = 'train_hour_day.csv'\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "get_hour = lambda db: db['OrderedDate'].apply(lambda x: x.split(' ')[1].split(':')[0]).astype('int64')\n",
    "get_day = lambda db: db['OrderedDate'].apply(lambda x: pd.to_datetime(x.split(' ')[0]).weekday()).astype('int64') \n",
    "#if use_hour:\n",
    "#    data['hour']= get_hour(data)\n",
    "#if use_day:\n",
    "#    data['day_of_week'] = get_day(data)\n",
    "    \n",
    "    \n",
    "TEST_PATH = 'test_hour_day.csv'\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "#if use_hour:\n",
    "#    test['hour']= get_hour(test)\n",
    "#if use_day:\n",
    "#    test['day_of_week'] = get_day(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if use_hour or use_day:\n",
    "#    data.to_csv('train{}.csv'.format(name_suf))\n",
    "#    test.to_csv('test{}.csv'.format(name_suf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = set(data['main_id_locality'])\n",
    "get_city = lambda frame, city, maket: frame[maket['main_id_locality'] == city]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADYC40cQ7dBu"
   },
   "outputs": [],
   "source": [
    "types = ['float64', 'int64'] if not use_linear else ['float64']\n",
    "values = data.select_dtypes(include = types)\n",
    "values = values.replace(\"NULL\", np.nan)\n",
    "result = values['RTA']\n",
    "del values['RTA']\n",
    "del values['RDA']\n",
    "\n",
    "if not use_linear:\n",
    "    del values['Id']\n",
    "    if not use_hour:\n",
    "        del values['hour']\n",
    "    if not use_day:\n",
    "        del values['day_of_week']\n",
    "    del values['main_id_locality']\n",
    "NOTNA = values.columns[values.notna().all()].tolist()\n",
    "values = values[NOTNA]\n",
    "vtest = test.select_dtypes(include = types)\n",
    "vtest =  vtest.replace(\"NULL\", np.nan)\n",
    "vtest = vtest[NOTNA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvalues = {city: get_city(values, city, data) for city in cities}\n",
    "cvtest = {city: get_city(vtest, city, test) for city in cities}\n",
    "cresult = {city: get_city(result, city, data) for city in cities}\n",
    "alllen = 0\n",
    "for city in cities:\n",
    "    alllen += len(data[data['main_id_locality'] == city])\n",
    "assert(alllen == len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1\n",
    "use_scaler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "beKo1kaw7mV0"
   },
   "outputs": [],
   "source": [
    "I = {}\n",
    "doubled = {}\n",
    "allData = {}\n",
    "cvtest2 = {}\n",
    "for city in cities:\n",
    "    X_train, X_test, y_train, y_test = selection.train_test_split(cvalues[city], cresult[city], \n",
    "                                                                            test_size=test_size, \n",
    "                                                                            random_state=random_state)\n",
    "    \n",
    "    if use_scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        eta = 0\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        cvtest[city] = scaler.transform(cvtest[city])\n",
    "        allData[city] = scaler.transform(cvalues[city])\n",
    "    else:\n",
    "        eta = 0\n",
    "        allData[city] = cvalues[city]\n",
    "    poly = PolynomialFeatures(2) \n",
    "    poly.fit(X_train)\n",
    "    \n",
    "    n_components = 8\n",
    "    pca = PCA(n_components= n_components, svd_solver='full')\n",
    "\n",
    "    X_train2 = poly.transform(X_train)\n",
    "    X_test2 = poly.transform(X_test)\n",
    "    pca.fit(X_train2, y_train)\n",
    "    X_train2 = pca.transform(X_train2)\n",
    "    X_test2 = pca.transform(X_test2)\n",
    "    cvtest2[city] = pca.transform(poly.transform(cvtest[city]))\n",
    "    \n",
    "    n_components = 6\n",
    "    pca = PCA(n_components= n_components, svd_solver='full')\n",
    "    pca.fit(X_train, y_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    cvtest[city] = pca.transform(cvtest[city])\n",
    "    tempI = {'Xtr': X_train,\n",
    "            'Xte': X_test,\n",
    "            'eta': eta,\n",
    "            'ytr': y_train,\n",
    "            'yte': y_test}\n",
    "    doubled[city] = {\n",
    "             'Xtr': X_train2,\n",
    "            'Xte': X_test2,\n",
    "            'ytr': y_train,\n",
    "            'yte': y_test\n",
    "    } \n",
    "    I[city] = tempI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQnPqgobIsDu"
   },
   "outputs": [],
   "source": [
    "Errors = {city: {'MEAN': metric(I[city]['eta'] + np.mean(I[city]['yte'] - I[city]['eta']), I[city]['yte'])} for city in cities}\n",
    "res_cl = {city: {} for city in cities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70yw2Nx3TTBl"
   },
   "outputs": [],
   "source": [
    "SGD = partial(linear_model.SGDRegressor, warm_start = True)\n",
    "Forest = partial(ensemble.RandomForestRegressor, warm_start= True)\n",
    "Boost = partial(ensemble.GradientBoostingRegressor, random_state = random_state, loss = 'lad', learning_rate = 0.15)\n",
    "Voting = partial(ensemble.VotingRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_dict(data, cl, **kwargs):\n",
    "    data['cl'] = partial(cl, **kwargs)\n",
    "    return data\n",
    "\n",
    "get_doubled = partial(get_classifier_dict, doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params = {'n_estimators = 300, learning_rate = 0.15': [300, 400, 500], 'learning_rate': [0.15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CiZU1_1I8sq"
   },
   "outputs": [],
   "source": [
    "#classifiers = {}\n",
    "#for n in Params['n_estimators']:\n",
    "#    for lr in Params['learning_rate']:\n",
    "#        classifiers['Boost_{}_{}'.format(n, lr)] = partial(Boost,  n_estimators = n, learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giant = partial(Voting, [('b3', Boost(max_depth = 5, random_state = 5, n_estimators = 300)),\n",
    "#                                       ('b1', Boost(max_depth = 6, random_state = 1, n_estimators = 200)), \n",
    "#                                       ('b2', Boost(max_depth = 8, random_state = 2, n_estimators = 200)),\n",
    "#    \n",
    "#classifiers = {'vot1320': partial(Voting, [('Boost', Boost(max_depth = 8, random_state = random_state, n_estimators = 200)),\n",
    "#                                       ('Lasso', Lasso()), \n",
    "#                                       ('Ridge', Ridge()),\n",
    "#                                        ('SGD', SGD()),\n",
    "#                                        ('Forest', Forest(max_depth = 7, random_state = random_state)),\n",
    "#                                         ('Boost2', Boost(max_depth = 6, random_state = 2*random_state, n_estimators = 300))\n",
    "#                                                           ])}\n",
    "classifiers = {'Boost1224': partial(Boost, max_depth = 8, n_estimators = 300)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Zau67vJ8JFVT",
    "outputId": "ac21af01-b24d-43c5-9380-b00d2bf7f71b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost1224\n",
      "City  22390\n"
     ]
    }
   ],
   "source": [
    "for name, classifier in classifiers.items():\n",
    "    print(name)\n",
    "    alllen = 0\n",
    "    ytr = I[city]['ytr']\n",
    "    xtr = I[city]['Xtr']\n",
    "    yte = I[city]['yte']\n",
    "    xte = I[city]['Xte']\n",
    "    cl = classifier\n",
    "    for city in cities:\n",
    "        if isinstance(cl, dict):\n",
    "            ytr = cl[city]['ytr']\n",
    "            xtr = cl[city]['Xtr']\n",
    "            yte = cl[city]['yte']\n",
    "            xte = cl[city]['Xte']\n",
    "            classifier = cl['cl']\n",
    "        print('City ', city)\n",
    "        temp_class = classifier()\n",
    "        temp_class.fit(xtr, ytr)\n",
    "        res_cl[city][name] = temp_class\n",
    "        predictions = temp_class.predict(xte)\n",
    "        err = metric(predictions, yte)\n",
    "        Errors[city][name] = err\n",
    "        print(err/len(predictions))\n",
    "        alllen += len(predictions)\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPQQRfjtvOew"
   },
   "outputs": [],
   "source": [
    "ErrorsAll = None\n",
    "for city in cities:\n",
    "    Ercit = Errors[city]\n",
    "    if ErrorsAll is None:\n",
    "        ErrorsAll = Ercit\n",
    "    else:\n",
    "        ErrorsAll = {name: er + Ercit[name] for name, er in ErrorsAll.items()}\n",
    "ErrorsAll = {name: er/alllen for name, er in ErrorsAll.items()}\n",
    "for key, value in ErrorsAll.items():\n",
    "    print('{}:  {}\\n'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for city in cities:\n",
    "#    Ercit = Errors[city]\n",
    "#    print(city)\n",
    "#    for key, value in Ercit.items():\n",
    "#        print('{}:   {}\\n'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for best_cl in classifiers.keys():\n",
    "    best_cls = {city: res_cl[city][best_cl] for city in cities}\n",
    "    tempres = {}\n",
    "    res = []\n",
    "    for city in cities:\n",
    "        tempres[city] = best_cls[city].predict(cvtest[city])\n",
    "    temp_idxs = {city: 0 for city in cities}\n",
    "    for idx, row in enumerate(test.itertuples()):\n",
    "        tempcity = row.main_id_locality\n",
    "        res.append(tempres[tempcity][temp_idxs[tempcity]])\n",
    "        temp_idxs[tempcity] += 1\n",
    "    fieldnames = ['ID', 'Prediction']\n",
    "    res = [{'ID': i, 'Prediction': r} for i, r in enumerate(res)]\n",
    "    import csv\n",
    "    OUT_PATH = 'output_{}.csv'.format(best_cl)\n",
    "    with open(OUT_PATH, 'w') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(res)\n",
    "    out = pd.read_csv(OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFLQQdFOBhFd"
   },
   "outputs": [],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
